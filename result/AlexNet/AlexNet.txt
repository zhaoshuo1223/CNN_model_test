time:
train_acc:
test_acc:


input:tensor(3,32,32)
一、结构：backbone： 5层卷积层：其中前两层带有最大池化且卷积核从11到5，应该是使用打卷积核，减少参数量。(实际不如VGG的连续的小卷积核)
                后三层的卷积核为3*3，用来提取特征。
                最后依旧是最大池化减少后续全连接层的参数量。
     
     flateen：降维
     tensor(128*1*1)

     head：三个全连接层：前两层带有激活函数增加非线性表达，以及dropout用来减少过拟合。
                        第三层用来映射到(batch_size,num_class)




二、
结论：1、AlexNet作为初代网络，纯粹的基础网络。
        相较于传统的视觉算法，可以不用对图片进行复杂处理，直接对图像进行学习。


2、与SimpleNet对比：acc基本持平
原因：虽然AlexNet更深，但是初期AlexNet存在降参操作，导致全连接的输入参数量远远小于SimpleNet的参数量
      但是AlexNet的收敛速度远快于SimpleNet，可能是网络深度的原因


